{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RokBLYLvwP7J",
        "outputId": "216e9ad3-1201-4dbf-e31e-f6d75da54cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_lr_finder\n",
            "  Downloading torch_lr_finder-0.2.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from torch_lr_finder) (1.13.1+cu116)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torch_lr_finder) (4.64.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from torch_lr_finder) (3.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch_lr_finder) (1.22.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from torch_lr_finder) (23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=0.4.1->torch_lr_finder) (4.5.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->torch_lr_finder) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->torch_lr_finder) (1.15.0)\n",
            "Installing collected packages: torch_lr_finder\n",
            "Successfully installed torch_lr_finder-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_lr_finder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rushi-the-neural-arch/EVA8-Assignments.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLjdRc38ZpLr",
        "outputId": "4b7f9afc-c93c-4693-d064-1915af07c06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'EVA8-Assignments' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EVA8-Assignments/Session_8/main.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vN5dyMNXw8oW",
        "outputId": "6801d54f-0c0a-4959-b577-fe1c3b4f6a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
            "         MaxPool2d-4          [-1, 128, 16, 16]               0\n",
            "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
            "            Conv2d-6          [-1, 128, 16, 16]         147,456\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "              ReLU-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-10          [-1, 128, 16, 16]             256\n",
            "             ReLU-11          [-1, 128, 16, 16]               0\n",
            "           Conv2d-12          [-1, 256, 16, 16]         294,912\n",
            "        MaxPool2d-13            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "           Conv2d-15            [-1, 512, 8, 8]       1,179,648\n",
            "        MaxPool2d-16            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-17            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-19            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-20            [-1, 512, 4, 4]               0\n",
            "           Conv2d-21            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-22            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 1, 1]               0\n",
            "           Linear-25                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 6,573,130\n",
            "Trainable params: 6,573,130\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.50\n",
            "Params size (MB): 25.07\n",
            "Estimated Total Size (MB): 30.59\n",
            "----------------------------------------------------------------\n",
            "None\n",
            " 94% 187/200 [00:46<00:02,  4.39it/s]Stopping early, the loss has diverged\n",
            " 94% 187/200 [00:46<00:03,  4.01it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 3.59E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.008490496046794983\n",
            "100% 200/200 [00:50<00:00,  3.93it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 3.73E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.008490496046794983\n",
            "100% 200/200 [00:50<00:00,  3.94it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 5.67E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.009164509905582627\n",
            "100% 200/200 [00:49<00:00,  4.03it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 3.59E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.007866053271078685\n",
            "100% 200/200 [00:49<00:00,  4.04it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 9.32E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.00989203002352568\n",
            "Determined min LR is: 0.007866053271078685\n",
            "EPOCH: 1 (LR: 7.866053271078686e-06)\n",
            "Batch_id=97 Loss=1.97837 Accuracy=31.71%: 100% 98/98 [00:24<00:00,  4.00it/s]\n",
            "\n",
            "Test set: Average loss: 1.3725, Accuracy: 5030/10000 (50.30%)\n",
            "\n",
            "EPOCH: 2 (LR: 0.0019774372741026523)\n",
            "Batch_id=97 Loss=1.25743 Accuracy=55.38%: 100% 98/98 [00:24<00:00,  4.02it/s]\n",
            "\n",
            "Test set: Average loss: 1.1189, Accuracy: 5977/10000 (59.77%)\n",
            "\n",
            "EPOCH: 3 (LR: 0.0039470084949342265)\n",
            "Batch_id=97 Loss=0.99939 Accuracy=64.90%: 100% 98/98 [00:24<00:00,  4.01it/s]\n",
            "\n",
            "Test set: Average loss: 0.8359, Accuracy: 7073/10000 (70.73%)\n",
            "\n",
            "EPOCH: 4 (LR: 0.005916579715765801)\n",
            "Batch_id=97 Loss=0.84857 Accuracy=70.27%: 100% 98/98 [00:25<00:00,  3.81it/s]\n",
            "\n",
            "Test set: Average loss: 0.8943, Accuracy: 6940/10000 (69.40%)\n",
            "\n",
            "EPOCH: 5 (LR: 0.007862039982606733)\n",
            "Batch_id=97 Loss=0.75671 Accuracy=73.76%: 100% 98/98 [00:25<00:00,  3.87it/s]\n",
            "\n",
            "Test set: Average loss: 0.6535, Accuracy: 7750/10000 (77.50%)\n",
            "\n",
            "EPOCH: 6 (LR: 0.007468737712355462)\n",
            "Batch_id=97 Loss=0.65475 Accuracy=77.39%: 100% 98/98 [00:24<00:00,  3.92it/s]\n",
            "\n",
            "Test set: Average loss: 0.5733, Accuracy: 8038/10000 (80.38%)\n",
            "\n",
            "EPOCH: 7 (LR: 0.0070754354421041915)\n",
            "Batch_id=97 Loss=0.58017 Accuracy=80.02%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.5607, Accuracy: 8060/10000 (80.60%)\n",
            "\n",
            "EPOCH: 8 (LR: 0.0066821331718529215)\n",
            "Batch_id=97 Loss=0.52599 Accuracy=81.68%: 100% 98/98 [00:25<00:00,  3.87it/s]\n",
            "\n",
            "Test set: Average loss: 0.5871, Accuracy: 8063/10000 (80.63%)\n",
            "\n",
            "EPOCH: 9 (LR: 0.006288830901601651)\n",
            "Batch_id=97 Loss=0.48727 Accuracy=83.22%: 100% 98/98 [00:24<00:00,  3.94it/s]\n",
            "\n",
            "Test set: Average loss: 0.5363, Accuracy: 8214/10000 (82.14%)\n",
            "\n",
            "EPOCH: 10 (LR: 0.00589552863135038)\n",
            "Batch_id=97 Loss=0.44147 Accuracy=84.87%: 100% 98/98 [00:25<00:00,  3.92it/s]\n",
            "\n",
            "Test set: Average loss: 0.4809, Accuracy: 8375/10000 (83.75%)\n",
            "\n",
            "EPOCH: 11 (LR: 0.00550222636109911)\n",
            "Batch_id=97 Loss=0.40849 Accuracy=85.72%: 100% 98/98 [00:25<00:00,  3.82it/s]\n",
            "\n",
            "Test set: Average loss: 0.4725, Accuracy: 8441/10000 (84.41%)\n",
            "\n",
            "EPOCH: 12 (LR: 0.005108924090847839)\n",
            "Batch_id=97 Loss=0.37720 Accuracy=86.87%: 100% 98/98 [00:25<00:00,  3.92it/s]\n",
            "\n",
            "Test set: Average loss: 0.4310, Accuracy: 8550/10000 (85.50%)\n",
            "\n",
            "EPOCH: 13 (LR: 0.004715621820596568)\n",
            "Batch_id=97 Loss=0.34529 Accuracy=87.98%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.4574, Accuracy: 8528/10000 (85.28%)\n",
            "\n",
            "EPOCH: 14 (LR: 0.004322319550345297)\n",
            "Batch_id=97 Loss=0.32714 Accuracy=88.68%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.4451, Accuracy: 8510/10000 (85.10%)\n",
            "\n",
            "EPOCH: 15 (LR: 0.003929017280094027)\n",
            "Batch_id=97 Loss=0.30191 Accuracy=89.44%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.4642, Accuracy: 8478/10000 (84.78%)\n",
            "\n",
            "EPOCH: 16 (LR: 0.003535715009842755)\n",
            "Batch_id=97 Loss=0.27942 Accuracy=90.42%: 100% 98/98 [00:24<00:00,  3.94it/s]\n",
            "\n",
            "Test set: Average loss: 0.4161, Accuracy: 8643/10000 (86.43%)\n",
            "\n",
            "EPOCH: 17 (LR: 0.0031424127395914842)\n",
            "Batch_id=97 Loss=0.25986 Accuracy=91.01%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.4043, Accuracy: 8648/10000 (86.48%)\n",
            "\n",
            "EPOCH: 18 (LR: 0.002749110469340214)\n",
            "Batch_id=97 Loss=0.24899 Accuracy=91.55%: 100% 98/98 [00:25<00:00,  3.84it/s]\n",
            "\n",
            "Test set: Average loss: 0.3973, Accuracy: 8696/10000 (86.96%)\n",
            "\n",
            "EPOCH: 19 (LR: 0.0023558081990889433)\n",
            "Batch_id=97 Loss=0.23057 Accuracy=92.09%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.3850, Accuracy: 8752/10000 (87.52%)\n",
            "\n",
            "EPOCH: 20 (LR: 0.0019625059288376732)\n",
            "Batch_id=97 Loss=0.20877 Accuracy=93.14%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.4264, Accuracy: 8667/10000 (86.67%)\n",
            "\n",
            "EPOCH: 21 (LR: 0.0015692036585864015)\n",
            "Batch_id=97 Loss=0.19765 Accuracy=93.35%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.3698, Accuracy: 8793/10000 (87.93%)\n",
            "\n",
            "EPOCH: 22 (LR: 0.0011759013883351306)\n",
            "Batch_id=97 Loss=0.17739 Accuracy=94.23%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.3629, Accuracy: 8806/10000 (88.06%)\n",
            "\n",
            "EPOCH: 23 (LR: 0.0007825991180838605)\n",
            "Batch_id=97 Loss=0.16849 Accuracy=94.41%: 100% 98/98 [00:25<00:00,  3.85it/s]\n",
            "\n",
            "Test set: Average loss: 0.3563, Accuracy: 8812/10000 (88.12%)\n",
            "\n",
            "EPOCH: 24 (LR: 0.00038929684783258964)\n",
            "Batch_id=97 Loss=0.15721 Accuracy=94.88%: 100% 98/98 [00:25<00:00,  3.87it/s]\n",
            "\n",
            "Test set: Average loss: 0.3479, Accuracy: 8847/10000 (88.47%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EVA8-Assignments/Session_8/main.py"
      ],
      "metadata": {
        "id": "kvuvVFIDw_zS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800a56a0-8ec0-4335-e1ae-d38b2044c8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
            "         MaxPool2d-4          [-1, 128, 16, 16]               0\n",
            "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
            "            Conv2d-6          [-1, 128, 16, 16]         147,456\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "              ReLU-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-10          [-1, 128, 16, 16]             256\n",
            "             ReLU-11          [-1, 128, 16, 16]               0\n",
            "           Conv2d-12          [-1, 256, 16, 16]         294,912\n",
            "        MaxPool2d-13            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "           Conv2d-15            [-1, 512, 8, 8]       1,179,648\n",
            "        MaxPool2d-16            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-17            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-19            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-20            [-1, 512, 4, 4]               0\n",
            "           Conv2d-21            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-22            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 1, 1]               0\n",
            "           Linear-25                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 6,573,130\n",
            "Trainable params: 6,573,130\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.50\n",
            "Params size (MB): 25.07\n",
            "Estimated Total Size (MB): 30.59\n",
            "----------------------------------------------------------------\n",
            "None\n",
            " 80% 161/200 [00:40<00:08,  4.41it/s]Stopping early, the loss has diverged\n",
            " 80% 161/200 [00:41<00:09,  3.92it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.74E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.008490496046794983\n",
            " 88% 175/200 [00:43<00:06,  4.03it/s]Stopping early, the loss has diverged\n",
            " 88% 175/200 [00:44<00:06,  3.95it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.54E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.008172312659337764\n",
            " 82% 163/200 [00:41<00:09,  4.11it/s]Stopping early, the loss has diverged\n",
            " 82% 163/200 [00:42<00:09,  3.88it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 3.59E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.011973631218639997\n",
            "100% 200/200 [00:50<00:00,  3.94it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.10E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.011093017474476805\n",
            " 91% 182/200 [00:46<00:04,  4.30it/s]Stopping early, the loss has diverged\n",
            " 91% 182/200 [00:46<00:04,  3.91it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.10E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.009521323812208146\n",
            "Determined min LR is: 0.009850156242291538\n",
            "EPOCH: 1 (LR: 0.0009850156242291537)\n",
            "Batch_id=97 Loss=1.75224 Accuracy=38.15%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 1.2513, Accuracy: 5528/10000 (55.28%)\n",
            "\n",
            "EPOCH: 2 (LR: 0.0032069690272217718)\n",
            "Batch_id=97 Loss=1.15192 Accuracy=59.01%: 100% 98/98 [00:24<00:00,  3.93it/s]\n",
            "\n",
            "Test set: Average loss: 0.9309, Accuracy: 6699/10000 (66.99%)\n",
            "\n",
            "EPOCH: 3 (LR: 0.005428922430214389)\n",
            "Batch_id=97 Loss=0.92534 Accuracy=67.56%: 100% 98/98 [00:24<00:00,  3.93it/s]\n",
            "\n",
            "Test set: Average loss: 1.0345, Accuracy: 6639/10000 (66.39%)\n",
            "\n",
            "EPOCH: 4 (LR: 0.007650875833207008)\n",
            "Batch_id=97 Loss=0.78594 Accuracy=72.84%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.7183, Accuracy: 7519/10000 (75.19%)\n",
            "\n",
            "EPOCH: 5 (LR: 0.00984514070355184)\n",
            "Batch_id=97 Loss=0.68400 Accuracy=76.48%: 100% 98/98 [00:26<00:00,  3.76it/s]\n",
            "\n",
            "Test set: Average loss: 0.5815, Accuracy: 8033/10000 (80.33%)\n",
            "\n",
            "EPOCH: 6 (LR: 0.009353617907061493)\n",
            "Batch_id=97 Loss=0.61476 Accuracy=78.72%: 100% 98/98 [00:25<00:00,  3.88it/s]\n",
            "\n",
            "Test set: Average loss: 0.7735, Accuracy: 7445/10000 (74.45%)\n",
            "\n",
            "EPOCH: 7 (LR: 0.008862095110571145)\n",
            "Batch_id=97 Loss=0.54976 Accuracy=81.00%: 100% 98/98 [00:25<00:00,  3.80it/s]\n",
            "\n",
            "Test set: Average loss: 0.5226, Accuracy: 8257/10000 (82.57%)\n",
            "\n",
            "EPOCH: 8 (LR: 0.008370572314080798)\n",
            "Batch_id=97 Loss=0.50070 Accuracy=82.65%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.5284, Accuracy: 8293/10000 (82.93%)\n",
            "\n",
            "EPOCH: 9 (LR: 0.007879049517590449)\n",
            "Batch_id=97 Loss=0.45143 Accuracy=84.48%: 100% 98/98 [00:25<00:00,  3.87it/s]\n",
            "\n",
            "Test set: Average loss: 0.4905, Accuracy: 8352/10000 (83.52%)\n",
            "\n",
            "EPOCH: 10 (LR: 0.007387526721100102)\n",
            "Batch_id=97 Loss=0.41665 Accuracy=85.51%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.5267, Accuracy: 8302/10000 (83.02%)\n",
            "\n",
            "EPOCH: 11 (LR: 0.006896003924609755)\n",
            "Batch_id=97 Loss=0.38633 Accuracy=86.79%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.4519, Accuracy: 8530/10000 (85.30%)\n",
            "\n",
            "EPOCH: 12 (LR: 0.006404481128119406)\n",
            "Batch_id=97 Loss=0.35427 Accuracy=87.68%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.4346, Accuracy: 8523/10000 (85.23%)\n",
            "\n",
            "EPOCH: 13 (LR: 0.005912958331629059)\n",
            "Batch_id=97 Loss=0.32542 Accuracy=88.78%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.4254, Accuracy: 8597/10000 (85.97%)\n",
            "\n",
            "EPOCH: 14 (LR: 0.005421435535138711)\n",
            "Batch_id=97 Loss=0.29762 Accuracy=89.66%: 100% 98/98 [00:25<00:00,  3.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.4263, Accuracy: 8651/10000 (86.51%)\n",
            "\n",
            "EPOCH: 15 (LR: 0.004929912738648364)\n",
            "Batch_id=97 Loss=0.27059 Accuracy=90.72%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.3904, Accuracy: 8744/10000 (87.44%)\n",
            "\n",
            "EPOCH: 16 (LR: 0.004438389942158015)\n",
            "Batch_id=97 Loss=0.25577 Accuracy=91.21%: 100% 98/98 [00:24<00:00,  3.93it/s]\n",
            "\n",
            "Test set: Average loss: 0.4082, Accuracy: 8670/10000 (86.70%)\n",
            "\n",
            "EPOCH: 17 (LR: 0.003946867145667667)\n",
            "Batch_id=97 Loss=0.23479 Accuracy=91.95%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.4110, Accuracy: 8701/10000 (87.01%)\n",
            "\n",
            "EPOCH: 18 (LR: 0.00345534434917732)\n",
            "Batch_id=97 Loss=0.21116 Accuracy=92.83%: 100% 98/98 [00:25<00:00,  3.85it/s]\n",
            "\n",
            "Test set: Average loss: 0.3724, Accuracy: 8793/10000 (87.93%)\n",
            "\n",
            "EPOCH: 19 (LR: 0.002963821552686972)\n",
            "Batch_id=97 Loss=0.19722 Accuracy=93.41%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.3652, Accuracy: 8791/10000 (87.91%)\n",
            "\n",
            "EPOCH: 20 (LR: 0.002472298756196625)\n",
            "Batch_id=97 Loss=0.18359 Accuracy=93.82%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.3796, Accuracy: 8816/10000 (88.16%)\n",
            "\n",
            "EPOCH: 21 (LR: 0.001980775959706277)\n",
            "Batch_id=97 Loss=0.16692 Accuracy=94.43%: 100% 98/98 [00:25<00:00,  3.79it/s]\n",
            "\n",
            "Test set: Average loss: 0.3626, Accuracy: 8849/10000 (88.49%)\n",
            "\n",
            "EPOCH: 22 (LR: 0.001489253163215928)\n",
            "Batch_id=97 Loss=0.15493 Accuracy=94.89%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.3649, Accuracy: 8868/10000 (88.68%)\n",
            "\n",
            "EPOCH: 23 (LR: 0.000997730366725581)\n",
            "Batch_id=97 Loss=0.13889 Accuracy=95.43%: 100% 98/98 [00:25<00:00,  3.82it/s]\n",
            "\n",
            "Test set: Average loss: 0.3424, Accuracy: 8900/10000 (89.00%)\n",
            "\n",
            "EPOCH: 24 (LR: 0.0005062075702352321)\n",
            "Batch_id=97 Loss=0.12989 Accuracy=95.92%: 100% 98/98 [00:27<00:00,  3.58it/s]\n",
            "\n",
            "Test set: Average loss: 0.3387, Accuracy: 8927/10000 (89.27%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python EVA8-Assignments/Session_8/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUJFiSYotUmZ",
        "outputId": "7061f0bd-3496-44ef-b7ea-f54202463a0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available: True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "            Conv2d-3          [-1, 128, 32, 32]          73,728\n",
            "         MaxPool2d-4          [-1, 128, 16, 16]               0\n",
            "       BatchNorm2d-5          [-1, 128, 16, 16]             256\n",
            "            Conv2d-6          [-1, 128, 16, 16]         147,456\n",
            "       BatchNorm2d-7          [-1, 128, 16, 16]             256\n",
            "              ReLU-8          [-1, 128, 16, 16]               0\n",
            "            Conv2d-9          [-1, 128, 16, 16]         147,456\n",
            "      BatchNorm2d-10          [-1, 128, 16, 16]             256\n",
            "             ReLU-11          [-1, 128, 16, 16]               0\n",
            "           Conv2d-12          [-1, 256, 16, 16]         294,912\n",
            "        MaxPool2d-13            [-1, 256, 8, 8]               0\n",
            "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
            "           Conv2d-15            [-1, 512, 8, 8]       1,179,648\n",
            "        MaxPool2d-16            [-1, 512, 4, 4]               0\n",
            "      BatchNorm2d-17            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-18            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-19            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-20            [-1, 512, 4, 4]               0\n",
            "           Conv2d-21            [-1, 512, 4, 4]       2,359,296\n",
            "      BatchNorm2d-22            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-23            [-1, 512, 4, 4]               0\n",
            "        MaxPool2d-24            [-1, 512, 1, 1]               0\n",
            "           Linear-25                   [-1, 10]           5,130\n",
            "================================================================\n",
            "Total params: 6,573,130\n",
            "Trainable params: 6,573,130\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.50\n",
            "Params size (MB): 25.07\n",
            "Estimated Total Size (MB): 30.59\n",
            "----------------------------------------------------------------\n",
            "None\n",
            " 86% 171/200 [00:42<00:07,  3.93it/s]Stopping early, the loss has diverged\n",
            " 86% 171/200 [00:42<00:07,  3.99it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 4.34E-01\n",
            "Figure(640x480)\n",
            "Max LR is 0.008490496046794983\n",
            "100% 200/200 [00:52<00:00,  3.83it/s]\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n",
            "LR suggestion: steepest gradient\n",
            "Suggested LR: 2.73E-02\n",
            "Figure(640x480)\n",
            "Max LR is 0.008200827696021389\n",
            "Determined Max LR is: 0.008200827696021389\n",
            "EPOCH: 1 (LR: 0.0008200827696021389)\n",
            "Batch_id=97 Loss=1.74791 Accuracy=38.16%: 100% 98/98 [00:24<00:00,  4.03it/s]\n",
            "\n",
            "Test set: Average loss: 1.2622, Accuracy: 5426/10000 (54.26%)\n",
            "\n",
            "EPOCH: 2 (LR: 0.0026699881475793423)\n",
            "Batch_id=97 Loss=1.15972 Accuracy=58.94%: 100% 98/98 [00:25<00:00,  3.92it/s]\n",
            "\n",
            "Test set: Average loss: 1.0173, Accuracy: 6383/10000 (63.83%)\n",
            "\n",
            "EPOCH: 3 (LR: 0.004519893525556546)\n",
            "Batch_id=97 Loss=0.94357 Accuracy=67.03%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.7931, Accuracy: 7207/10000 (72.07%)\n",
            "\n",
            "EPOCH: 4 (LR: 0.006369798903533748)\n",
            "Batch_id=97 Loss=0.80020 Accuracy=72.18%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.7057, Accuracy: 7501/10000 (75.01%)\n",
            "\n",
            "EPOCH: 5 (LR: 0.00819665196844964)\n",
            "Batch_id=97 Loss=0.71365 Accuracy=75.26%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.6757, Accuracy: 7682/10000 (76.82%)\n",
            "\n",
            "EPOCH: 6 (LR: 0.007787430666418172)\n",
            "Batch_id=97 Loss=0.61648 Accuracy=78.81%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.5783, Accuracy: 8011/10000 (80.11%)\n",
            "\n",
            "EPOCH: 7 (LR: 0.007378209364386705)\n",
            "Batch_id=97 Loss=0.56270 Accuracy=80.58%: 100% 98/98 [00:25<00:00,  3.80it/s]\n",
            "\n",
            "Test set: Average loss: 0.5376, Accuracy: 8153/10000 (81.53%)\n",
            "\n",
            "EPOCH: 8 (LR: 0.006968988062355237)\n",
            "Batch_id=97 Loss=0.50364 Accuracy=82.55%: 100% 98/98 [00:25<00:00,  3.89it/s]\n",
            "\n",
            "Test set: Average loss: 0.5482, Accuracy: 8185/10000 (81.85%)\n",
            "\n",
            "EPOCH: 9 (LR: 0.00655976676032377)\n",
            "Batch_id=97 Loss=0.46490 Accuracy=83.88%: 100% 98/98 [00:24<00:00,  3.93it/s]\n",
            "\n",
            "Test set: Average loss: 0.4853, Accuracy: 8358/10000 (83.58%)\n",
            "\n",
            "EPOCH: 10 (LR: 0.006150545458292302)\n",
            "Batch_id=97 Loss=0.42658 Accuracy=85.13%: 100% 98/98 [00:24<00:00,  3.95it/s]\n",
            "\n",
            "Test set: Average loss: 0.4931, Accuracy: 8370/10000 (83.70%)\n",
            "\n",
            "EPOCH: 11 (LR: 0.005741324156260835)\n",
            "Batch_id=97 Loss=0.39857 Accuracy=86.09%: 100% 98/98 [00:24<00:00,  3.95it/s]\n",
            "\n",
            "Test set: Average loss: 0.4562, Accuracy: 8507/10000 (85.07%)\n",
            "\n",
            "EPOCH: 12 (LR: 0.005332102854229368)\n",
            "Batch_id=97 Loss=0.36918 Accuracy=87.45%: 100% 98/98 [00:24<00:00,  3.96it/s]\n",
            "\n",
            "Test set: Average loss: 0.4947, Accuracy: 8375/10000 (83.75%)\n",
            "\n",
            "EPOCH: 13 (LR: 0.004922881552197901)\n",
            "Batch_id=97 Loss=0.34452 Accuracy=88.12%: 100% 98/98 [00:25<00:00,  3.88it/s]\n",
            "\n",
            "Test set: Average loss: 0.4460, Accuracy: 8520/10000 (85.20%)\n",
            "\n",
            "EPOCH: 14 (LR: 0.004513660250166433)\n",
            "Batch_id=97 Loss=0.32204 Accuracy=89.01%: 100% 98/98 [00:24<00:00,  3.97it/s]\n",
            "\n",
            "Test set: Average loss: 0.5000, Accuracy: 8443/10000 (84.43%)\n",
            "\n",
            "EPOCH: 15 (LR: 0.0041044389481349666)\n",
            "Batch_id=97 Loss=0.30339 Accuracy=89.58%: 100% 98/98 [00:25<00:00,  3.91it/s]\n",
            "\n",
            "Test set: Average loss: 0.4491, Accuracy: 8525/10000 (85.25%)\n",
            "\n",
            "EPOCH: 16 (LR: 0.0036952176461034986)\n",
            "Batch_id=97 Loss=0.27832 Accuracy=90.49%: 100% 98/98 [00:25<00:00,  3.87it/s]\n",
            "\n",
            "Test set: Average loss: 0.4039, Accuracy: 8661/10000 (86.61%)\n",
            "\n",
            "EPOCH: 17 (LR: 0.0032859963440720306)\n",
            "Batch_id=97 Loss=0.24912 Accuracy=91.53%: 100% 98/98 [00:24<00:00,  3.97it/s]\n",
            "\n",
            "Test set: Average loss: 0.3906, Accuracy: 8725/10000 (87.25%)\n",
            "\n",
            "EPOCH: 18 (LR: 0.0028767750420405636)\n",
            "Batch_id=97 Loss=0.23311 Accuracy=92.04%: 100% 98/98 [00:25<00:00,  3.90it/s]\n",
            "\n",
            "Test set: Average loss: 0.3901, Accuracy: 8754/10000 (87.54%)\n",
            "\n",
            "EPOCH: 19 (LR: 0.0024675537400090965)\n",
            "Batch_id=97 Loss=0.21655 Accuracy=92.62%: 100% 98/98 [00:24<00:00,  3.94it/s]\n",
            "\n",
            "Test set: Average loss: 0.3859, Accuracy: 8772/10000 (87.72%)\n",
            "\n",
            "EPOCH: 20 (LR: 0.0020583324379776294)\n",
            "Batch_id=97 Loss=0.20754 Accuracy=92.87%: 100% 98/98 [00:25<00:00,  3.86it/s]\n",
            "\n",
            "Test set: Average loss: 0.3744, Accuracy: 8774/10000 (87.74%)\n",
            "\n",
            "EPOCH: 21 (LR: 0.0016491111359461614)\n",
            "Batch_id=97 Loss=0.18718 Accuracy=93.77%: 100% 98/98 [00:24<00:00,  3.98it/s]\n",
            "\n",
            "Test set: Average loss: 0.3639, Accuracy: 8830/10000 (88.30%)\n",
            "\n",
            "EPOCH: 22 (LR: 0.0012398898339146943)\n",
            "Batch_id=97 Loss=0.17049 Accuracy=94.42%: 100% 98/98 [00:24<00:00,  3.97it/s]\n",
            "\n",
            "Test set: Average loss: 0.3513, Accuracy: 8856/10000 (88.56%)\n",
            "\n",
            "EPOCH: 23 (LR: 0.0008306685318832272)\n",
            "Batch_id=97 Loss=0.15979 Accuracy=94.77%: 100% 98/98 [00:24<00:00,  3.97it/s]\n",
            "\n",
            "Test set: Average loss: 0.3473, Accuracy: 8883/10000 (88.83%)\n",
            "\n",
            "EPOCH: 24 (LR: 0.0004214472298517593)\n",
            "Batch_id=97 Loss=0.15001 Accuracy=95.18%: 100% 98/98 [00:24<00:00,  3.98it/s]\n",
            "\n",
            "Test set: Average loss: 0.3422, Accuracy: 8901/10000 (89.01%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}